{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOpJx39XL7vCN+svx6QK5DM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"NgEfNrwToPkJ"},"outputs":[],"source":["import pandas as pd\n","import tensorflow as tf\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","source":["#@title Define the functions that build and train a model\n","def build_model(my_learning_rate):\n","  \"\"\"Create and compile a simple linear regression model.\"\"\"\n","  # Most simple tf.keras models are sequential.\n","  # A sequential model contains one or more layers.\n","  model = tf.keras.models.Sequential()\n","\n","  # Describe the topography of the model.\n","  # The topography of a simple linear regression model\n","  # is a single node in a single layer.\n","  model.add(tf.keras.layers.Dense(units=1,\n","                                  input_shape=(1,)))\n","\n","  # Compile the model topography into code that\n","  # TensorFlow can efficiently execute. Configure\n","  # training to minimize the model's mean squared error.\n","  model.compile(optimizer=tf.keras.optimizers.experimental.RMSprop(learning_rate=my_learning_rate),\n","                loss=\"mean_squared_error\",\n","                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n","\n","  return model\n","\n","\n","def train_model(model, feature, label, epochs, batch_size):\n","  \"\"\"Train the model by feeding it data.\"\"\"\n","\n","  # Feed the feature values and the label values to the\n","  # model. The model will train for the specified number\n","  # of epochs, gradually learning how the feature values\n","  # relate to the label values.\n","  history = model.fit(x=feature,\n","                      y=label,\n","                      batch_size=batch_size,\n","                      epochs=epochs)\n","\n","  # Gather the trained model's weight and bias.\n","  trained_weight = model.get_weights()[0]\n","  trained_bias = model.get_weights()[1]\n","\n","  # The list of epochs is stored separately from the\n","  # rest of history.\n","  epochs = history.epoch\n","\n","  # Gather the history (a snapshot) of each epoch.\n","  hist = pd.DataFrame(history.history)\n","\n","  # Specifically gather the model's root mean\n","  # squared error at each epoch.\n","  rmse = hist[\"root_mean_squared_error\"]\n","\n","  return trained_weight, trained_bias, epochs, rmse\n","\n","print(\"Defined build_model and train_model\")"],"metadata":{"id":"vSy5OSoHoZ_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Define the plotting functions\n","def plot_the_model(trained_weight, trained_bias, feature, label):\n","  \"\"\"Plot the trained model against the training feature and label.\"\"\"\n","\n","  # Label the axes.\n","  plt.xlabel(\"feature\")\n","  plt.ylabel(\"label\")\n","\n","  # Plot the feature values vs. label values.\n","  plt.scatter(feature, label)\n","\n","  # Create a red line representing the model. The red line starts\n","  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n","  x0 = 0\n","  y0 = trained_bias\n","  x1 = feature[-1]\n","  y1 = trained_bias + (trained_weight * x1)\n","  plt.plot([x0, x1], [y0, y1], c='r')\n","\n","  # Render the scatter plot and the red line.\n","  plt.show()\n","\n","def plot_the_loss_curve(epochs, rmse):\n","  \"\"\"Plot the loss curve, which shows loss vs. epoch.\"\"\"\n","\n","  plt.figure()\n","  plt.xlabel(\"Epoch\")\n","  plt.ylabel(\"Root Mean Squared Error\")\n","\n","  plt.plot(epochs, rmse, label=\"Loss\")\n","  plt.legend()\n","  plt.ylim([rmse.min()*0.97, rmse.max()])\n","  plt.show()\n","\n","print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"],"metadata":{"id":"8Hw-fxBKodOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["my_feature = ([1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0])\n","my_label   = ([5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2])"],"metadata":{"id":"d_3en3yxohkP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate=0.01\n","epochs=10\n","my_batch_size=12\n","\n","my_model = build_model(learning_rate)\n","trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n","                                                         my_label, epochs,\n","                                                         my_batch_size)\n","plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n","plot_the_loss_curve(epochs, rmse)"],"metadata":{"id":"8Ibzm0zEokJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate=0.01\n","epochs=450\n","my_batch_size=12\n","\n","my_model = build_model(learning_rate)\n","trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n","                                                         my_label, epochs,\n","                                                         my_batch_size)\n","plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n","plot_the_loss_curve(epochs, rmse)\n","\n","# The loss curve suggests that the model does converge."],"metadata":{"id":"VhMUyHAJotIq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Increase the learning rate and decrease the number of epochs.\n","learning_rate=100\n","epochs=500\n","\n","my_model = build_model(learning_rate)\n","trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n","                                                         my_label, epochs,\n","                                                         my_batch_size)\n","plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n","plot_the_loss_curve(epochs, rmse)"],"metadata":{"id":"PAJHPenQoxRr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate=0.14\n","epochs=70\n","\n","my_model = build_model(learning_rate)\n","trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n","                                                         my_label, epochs,\n","                                                         my_batch_size)\n","plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n","plot_the_loss_curve(epochs, rmse)"],"metadata":{"id":"0pNeCnoXoyUm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["learning_rate=0.05\n","epochs=125\n","my_batch_size=1 # Wow, a batch size of 1 works!\n","\n","my_model = build_model(learning_rate)\n","trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature,\n","                                                         my_label, epochs,\n","                                                         my_batch_size)\n","plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n","plot_the_loss_curve(epochs, rmse)\n"],"metadata":{"id":"9q0-5855o1P1"},"execution_count":null,"outputs":[]}]}